{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jittapont/bank_proof_classification/blob/master/Image_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5xfgvVBrZSP",
        "colab_type": "code",
        "outputId": "a34f3fb0-4020-42e7-b845-459ee534f60b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B01cctcvcwzt",
        "colab_type": "code",
        "outputId": "02f37f3a-5077-45ad-97b3-951c0d17ff9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvM-I9viq7AF",
        "colab_type": "code",
        "outputId": "1e1de3de-9514-43bd-c454-0d194f9e7eb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "import pickle\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import datetime\n",
        "%tensorflow_version 1.15.0"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: `1.x` or `2.x`.\n",
            "You set: `1.15.0`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SE2-vi_WqbRw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"/content/drive/My Drive/Dataset/X.pickle\",\"rb\") as pickle_in:\n",
        "    X = pickle.load(pickle_in)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEPoo6rRq-yB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"/content/drive/My Drive/Dataset/y.pickle\",\"rb\") as pickle_in:\n",
        "    y = pickle.load(pickle_in)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsH8j_G9CU7y",
        "colab_type": "code",
        "outputId": "942daf5c-ffaa-49b3-e45c-1d009cad8cf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(44000, 100, 100, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ag6vHGYJkTyx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = to_categorical(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnhLE6yWiI_h",
        "colab_type": "code",
        "outputId": "308b1e1e-37df-4293-dcd4-54f3cd7a477a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "source": [
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn't guaranteed\n",
        "gpu = GPUs[0]\n",
        "\n",
        "def printm():\n",
        "  process = psutil.Process(os.getpid())\n",
        "  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" I Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "  print('GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB'.format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "\n",
        "printm()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Gen RAM Free: 9.1 GB  I Proc size: 5.0 GB\n",
            "GPU RAM Free: 11370MB | Used: 71MB | Util   1% | Total 11441MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Fb8wfbN00Jj",
        "colab_type": "code",
        "outputId": "3ad07a1c-b7b3-4264-ae27-f507701745d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), input_shape=X.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(64))\n",
        "model.add(Dense(64))\n",
        "\n",
        "model.add(Dense(y.shape[1]))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X, y, batch_size=128, epochs=30, validation_split=0.3)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 30799 samples, validate on 13201 samples\n",
            "Epoch 1/30\n",
            "30799/30799 [==============================] - 39s 1ms/sample - loss: 0.1703 - acc: 0.9506 - val_loss: 0.0190 - val_acc: 0.9964\n",
            "Epoch 2/30\n",
            "30799/30799 [==============================] - 38s 1ms/sample - loss: 0.0171 - acc: 0.9963 - val_loss: 0.0129 - val_acc: 0.9973\n",
            "Epoch 3/30\n",
            "30799/30799 [==============================] - 38s 1ms/sample - loss: 0.0068 - acc: 0.9984 - val_loss: 0.0095 - val_acc: 0.9987\n",
            "Epoch 4/30\n",
            "30799/30799 [==============================] - 38s 1ms/sample - loss: 0.0018 - acc: 0.9996 - val_loss: 0.0088 - val_acc: 0.9985\n",
            "Epoch 5/30\n",
            "30799/30799 [==============================] - 38s 1ms/sample - loss: 0.0029 - acc: 0.9993 - val_loss: 0.0109 - val_acc: 0.9985\n",
            "Epoch 6/30\n",
            "30799/30799 [==============================] - 38s 1ms/sample - loss: 0.0013 - acc: 0.9996 - val_loss: 0.0141 - val_acc: 0.9983\n",
            "Epoch 7/30\n",
            "30799/30799 [==============================] - 38s 1ms/sample - loss: 0.0026 - acc: 0.9993 - val_loss: 0.0141 - val_acc: 0.9978\n",
            "Epoch 8/30\n",
            "30799/30799 [==============================] - 38s 1ms/sample - loss: 0.0966 - acc: 0.9841 - val_loss: 0.0149 - val_acc: 0.9979\n",
            "Epoch 9/30\n",
            "30799/30799 [==============================] - 38s 1ms/sample - loss: 0.0047 - acc: 0.9989 - val_loss: 0.0127 - val_acc: 0.9986\n",
            "Epoch 10/30\n",
            "30799/30799 [==============================] - 38s 1ms/sample - loss: 7.8967e-04 - acc: 0.9998 - val_loss: 0.0151 - val_acc: 0.9983\n",
            "Epoch 11/30\n",
            "30799/30799 [==============================] - 38s 1ms/sample - loss: 0.0011 - acc: 0.9996 - val_loss: 0.0273 - val_acc: 0.9955\n",
            "Epoch 12/30\n",
            "30799/30799 [==============================] - 37s 1ms/sample - loss: 0.0035 - acc: 0.9991 - val_loss: 0.0164 - val_acc: 0.9979\n",
            "Epoch 13/30\n",
            "30799/30799 [==============================] - 37s 1ms/sample - loss: 0.0025 - acc: 0.9996 - val_loss: 0.0120 - val_acc: 0.9987\n",
            "Epoch 14/30\n",
            "30799/30799 [==============================] - 37s 1ms/sample - loss: 0.0014 - acc: 0.9999 - val_loss: 0.0116 - val_acc: 0.9987\n",
            "Epoch 15/30\n",
            "30799/30799 [==============================] - 37s 1ms/sample - loss: 9.2899e-04 - acc: 0.9998 - val_loss: 0.0117 - val_acc: 0.9988\n",
            "Epoch 16/30\n",
            "30799/30799 [==============================] - 38s 1ms/sample - loss: 6.5247e-04 - acc: 0.9999 - val_loss: 0.0127 - val_acc: 0.9989\n",
            "Epoch 17/30\n",
            "30799/30799 [==============================] - 38s 1ms/sample - loss: 6.1356e-04 - acc: 0.9999 - val_loss: 0.0124 - val_acc: 0.9986\n",
            "Epoch 18/30\n",
            "30799/30799 [==============================] - 37s 1ms/sample - loss: 7.7733e-04 - acc: 1.0000 - val_loss: 0.0105 - val_acc: 0.9989\n",
            "Epoch 19/30\n",
            "30799/30799 [==============================] - 37s 1ms/sample - loss: 1.9350e-04 - acc: 0.9999 - val_loss: 0.0103 - val_acc: 0.9991\n",
            "Epoch 20/30\n",
            "30799/30799 [==============================] - 37s 1ms/sample - loss: 3.7684e-04 - acc: 0.9999 - val_loss: 0.0150 - val_acc: 0.9983\n",
            "Epoch 21/30\n",
            "30799/30799 [==============================] - 38s 1ms/sample - loss: 9.7915e-04 - acc: 0.9998 - val_loss: 0.0129 - val_acc: 0.9989\n",
            "Epoch 22/30\n",
            "30799/30799 [==============================] - 37s 1ms/sample - loss: 2.1077e-05 - acc: 1.0000 - val_loss: 0.0127 - val_acc: 0.9991\n",
            "Epoch 23/30\n",
            "30799/30799 [==============================] - 37s 1ms/sample - loss: 8.2705e-06 - acc: 1.0000 - val_loss: 0.0131 - val_acc: 0.9991\n",
            "Epoch 24/30\n",
            "30799/30799 [==============================] - 37s 1ms/sample - loss: 6.0947e-06 - acc: 1.0000 - val_loss: 0.0132 - val_acc: 0.9990\n",
            "Epoch 25/30\n",
            "30799/30799 [==============================] - 38s 1ms/sample - loss: 4.5163e-06 - acc: 1.0000 - val_loss: 0.0134 - val_acc: 0.9992\n",
            "Epoch 26/30\n",
            "30799/30799 [==============================] - 37s 1ms/sample - loss: 3.7770e-06 - acc: 1.0000 - val_loss: 0.0134 - val_acc: 0.9991\n",
            "Epoch 27/30\n",
            "30799/30799 [==============================] - 37s 1ms/sample - loss: 3.0009e-06 - acc: 1.0000 - val_loss: 0.0137 - val_acc: 0.9992\n",
            "Epoch 28/30\n",
            "30799/30799 [==============================] - 37s 1ms/sample - loss: 2.5261e-06 - acc: 1.0000 - val_loss: 0.0138 - val_acc: 0.9992\n",
            "Epoch 29/30\n",
            "30799/30799 [==============================] - 37s 1ms/sample - loss: 2.0676e-06 - acc: 1.0000 - val_loss: 0.0140 - val_acc: 0.9992\n",
            "Epoch 30/30\n",
            "30799/30799 [==============================] - 38s 1ms/sample - loss: 1.8075e-06 - acc: 1.0000 - val_loss: 0.0141 - val_acc: 0.9992\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fafea3afb00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMGU5j0OnE3l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_path = r'/content/drive/My Drive/OCR scripts'\n",
        "model.save(os.path.join(\n",
        "    model_path,\n",
        "    f\"image_classification_model_{datetime.datetime.now().strftime('%Y-%m-%d')}.model\")\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUXrjhXX91Q8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\n",
        "    f\"image_classification_model_{datetime.datetime.now().strftime('%Y-%m-%d')}.model\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNGUbvbn34Dv",
        "colab_type": "code",
        "outputId": "ae53c8a2-fe84-4374-b7f4-ca4d93bda05d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import cv2\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "categories = ['BAY', 'BBL', 'GSB', 'KBANK', 'KTB', 'Others', 'SCB', 'TBANK', 'TMB']\n",
        "\n",
        "def prepare(filepath):\n",
        "    IMG_SIZE = 100\n",
        "    img_array = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
        "    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE)) \n",
        "    return new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 1) \n",
        "\n",
        "model = tf.keras.models.load_model(\"/content/Image_Classification.model\")\n",
        "prediction = model.predict([prepare('/content/678941063_14863738349228379046.jpeg')])\n",
        "print(prediction[0])\n",
        "print(categories[np.argmax(prediction[0])])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "KBANK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOUpHJFt4YwW",
        "colab_type": "code",
        "outputId": "36b06b17-6213-4d5c-ac30-d44bdd41982f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "prediction[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 1., 0., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    }
  ]
}