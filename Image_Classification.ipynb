{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jittapont/bank_proof_classification/blob/master/Image_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5xfgvVBrZSP",
        "colab_type": "code",
        "outputId": "a34f3fb0-4020-42e7-b845-459ee534f60b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B01cctcvcwzt",
        "colab_type": "code",
        "outputId": "02f37f3a-5077-45ad-97b3-951c0d17ff9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvM-I9viq7AF",
        "colab_type": "code",
        "outputId": "1e1de3de-9514-43bd-c454-0d194f9e7eb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "import pickle\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import datetime\n",
        "%tensorflow_version 1.15.0"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: `1.x` or `2.x`.\n",
            "You set: `1.15.0`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SE2-vi_WqbRw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"/content/drive/My Drive/Dataset/X.pickle\",\"rb\") as pickle_in:\n",
        "    X = pickle.load(pickle_in)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEPoo6rRq-yB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"/content/drive/My Drive/Dataset/y.pickle\",\"rb\") as pickle_in:\n",
        "    y = pickle.load(pickle_in)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsH8j_G9CU7y",
        "colab_type": "code",
        "outputId": "942daf5c-ffaa-49b3-e45c-1d009cad8cf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(44000, 100, 100, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ag6vHGYJkTyx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = to_categorical(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnhLE6yWiI_h",
        "colab_type": "code",
        "outputId": "308b1e1e-37df-4293-dcd4-54f3cd7a477a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "source": [
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn't guaranteed\n",
        "gpu = GPUs[0]\n",
        "\n",
        "def printm():\n",
        "  process = psutil.Process(os.getpid())\n",
        "  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" I Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "  print('GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB'.format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "\n",
        "printm()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Gen RAM Free: 9.1 GB  I Proc size: 5.0 GB\n",
            "GPU RAM Free: 11370MB | Used: 71MB | Util   1% | Total 11441MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Fb8wfbN00Jj",
        "colab_type": "code",
        "outputId": "645afc05-a749-453c-9577-f17c4b6c9f14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 796
        }
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), input_shape=X.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(64))\n",
        "model.add(Dense(64))\n",
        "\n",
        "model.add(Dense(y.shape[1]))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X, y, batch_size=128, epochs=30, validation_split=0.3)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Train on 30799 samples, validate on 13201 samples\n",
            "Epoch 1/20\n",
            "30799/30799 [==============================] - 44s 1ms/sample - loss: 0.2206 - acc: 0.9369 - val_loss: 0.0444 - val_acc: 0.9889\n",
            "Epoch 2/20\n",
            "30799/30799 [==============================] - 38s 1ms/sample - loss: 0.0146 - acc: 0.9967 - val_loss: 0.0179 - val_acc: 0.9955\n",
            "Epoch 3/20\n",
            "30799/30799 [==============================] - 38s 1ms/sample - loss: 0.0039 - acc: 0.9991 - val_loss: 0.0103 - val_acc: 0.9983\n",
            "Epoch 4/20\n",
            "30799/30799 [==============================] - 38s 1ms/sample - loss: 0.0026 - acc: 0.9995 - val_loss: 0.0092 - val_acc: 0.9988\n",
            "Epoch 5/20\n",
            "30799/30799 [==============================] - 38s 1ms/sample - loss: 0.0017 - acc: 0.9996 - val_loss: 0.0177 - val_acc: 0.9973\n",
            "Epoch 6/20\n",
            "30799/30799 [==============================] - 38s 1ms/sample - loss: 0.0532 - acc: 0.9888 - val_loss: 0.0181 - val_acc: 0.9960\n",
            "Epoch 7/20\n",
            "30799/30799 [==============================] - 41s 1ms/sample - loss: 0.0045 - acc: 0.9990 - val_loss: 0.0137 - val_acc: 0.9981\n",
            "Epoch 8/20\n",
            "30799/30799 [==============================] - 38s 1ms/sample - loss: 0.0011 - acc: 0.9997 - val_loss: 0.0138 - val_acc: 0.9981\n",
            "Epoch 9/20\n",
            "30799/30799 [==============================] - 38s 1ms/sample - loss: 7.9363e-04 - acc: 0.9999 - val_loss: 0.0146 - val_acc: 0.9983\n",
            "Epoch 10/20\n",
            "30799/30799 [==============================] - 38s 1ms/sample - loss: 2.1471e-04 - acc: 0.9999 - val_loss: 0.0152 - val_acc: 0.9983\n",
            "Epoch 11/20\n",
            "30799/30799 [==============================] - 38s 1ms/sample - loss: 0.0035 - acc: 0.9991 - val_loss: 0.0179 - val_acc: 0.9980\n",
            "Epoch 12/20\n",
            "30799/30799 [==============================] - 38s 1ms/sample - loss: 0.0016 - acc: 0.9995 - val_loss: 0.0173 - val_acc: 0.9983\n",
            "Epoch 13/20\n",
            "30799/30799 [==============================] - 38s 1ms/sample - loss: 8.3425e-04 - acc: 0.9999 - val_loss: 0.0143 - val_acc: 0.9986\n",
            "Epoch 14/20\n",
            "30799/30799 [==============================] - 38s 1ms/sample - loss: 2.8905e-05 - acc: 1.0000 - val_loss: 0.0146 - val_acc: 0.9986\n",
            "Epoch 15/20\n",
            "30799/30799 [==============================] - 38s 1ms/sample - loss: 1.6753e-05 - acc: 1.0000 - val_loss: 0.0152 - val_acc: 0.9987\n",
            "Epoch 16/20\n",
            "30799/30799 [==============================] - 38s 1ms/sample - loss: 1.1788e-05 - acc: 1.0000 - val_loss: 0.0156 - val_acc: 0.9987\n",
            "Epoch 17/20\n",
            "30799/30799 [==============================] - 38s 1ms/sample - loss: 9.0340e-06 - acc: 1.0000 - val_loss: 0.0160 - val_acc: 0.9987\n",
            "Epoch 18/20\n",
            "30799/30799 [==============================] - 38s 1ms/sample - loss: 7.3065e-06 - acc: 1.0000 - val_loss: 0.0162 - val_acc: 0.9986\n",
            "Epoch 19/20\n",
            "30799/30799 [==============================] - 38s 1ms/sample - loss: 5.8374e-06 - acc: 1.0000 - val_loss: 0.0165 - val_acc: 0.9986\n",
            "Epoch 20/20\n",
            "30799/30799 [==============================] - 38s 1ms/sample - loss: 4.8282e-06 - acc: 1.0000 - val_loss: 0.0167 - val_acc: 0.9986\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb043a6a710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMGU5j0OnE3l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_path = r'/content/drive/My Drive/OCR scripts'\n",
        "model.save(os.path.join(\n",
        "    model_path,\n",
        "    f\"image_classification_model_{datetime.datetime.now().strftime('%Y-%m-%d')}.model\")\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUXrjhXX91Q8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\n",
        "    f\"image_classification_model_{datetime.datetime.now().strftime('%Y-%m-%d')}.model\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNGUbvbn34Dv",
        "colab_type": "code",
        "outputId": "ae53c8a2-fe84-4374-b7f4-ca4d93bda05d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import cv2\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "categories = ['BAY', 'BBL', 'GSB', 'KBANK', 'KTB', 'Others', 'SCB', 'TBANK', 'TMB']\n",
        "\n",
        "def prepare(filepath):\n",
        "    IMG_SIZE = 100\n",
        "    img_array = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
        "    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE)) \n",
        "    return new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 1) \n",
        "\n",
        "model = tf.keras.models.load_model(\"/content/Image_Classification.model\")\n",
        "prediction = model.predict([prepare('/content/678941063_14863738349228379046.jpeg')])\n",
        "print(prediction[0])\n",
        "print(categories[np.argmax(prediction[0])])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "KBANK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOUpHJFt4YwW",
        "colab_type": "code",
        "outputId": "36b06b17-6213-4d5c-ac30-d44bdd41982f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "prediction[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 1., 0., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    }
  ]
}