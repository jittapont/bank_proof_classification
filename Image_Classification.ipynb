{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jittapont/bank_proof_classification/blob/master/Image_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5xfgvVBrZSP",
        "colab_type": "code",
        "outputId": "8dce7b91-44d5-46d9-cbd6-87e8f41e0360",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B01cctcvcwzt",
        "colab_type": "code",
        "outputId": "02f37f3a-5077-45ad-97b3-951c0d17ff9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvM-I9viq7AF",
        "colab_type": "code",
        "outputId": "998a2b1f-c144-4bbd-8afb-d1e651975a44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import pickle\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import datetime"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SE2-vi_WqbRw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"/content/drive/My Drive/Dataset/X.pickle\",\"rb\") as pickle_in:\n",
        "    X = pickle.load(pickle_in)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEPoo6rRq-yB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"/content/drive/My Drive/Dataset/y.pickle\",\"rb\") as pickle_in:\n",
        "    y = pickle.load(pickle_in)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsH8j_G9CU7y",
        "colab_type": "code",
        "outputId": "b9925ea9-fb77-4dd7-f5c1-65d6e2b5a589",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(44000, 100, 100, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ag6vHGYJkTyx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = to_categorical(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnhLE6yWiI_h",
        "colab_type": "code",
        "outputId": "c05bddf3-c483-4f26-cb15-bfadce137501",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        }
      },
      "source": [
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn't guaranteed\n",
        "gpu = GPUs[0]\n",
        "\n",
        "def printm():\n",
        "  process = psutil.Process(os.getpid())\n",
        "  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" I Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "  print('GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB'.format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "\n",
        "printm()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7410 sha256=5b23d258aca0774453554bfd0f047ff8f3ee71e02b6bc72ddbf117c628f591cf\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Gen RAM Free: 22.6 GB  I Proc size: 7.4 GB\n",
            "GPU RAM Free: 16280MB | Used: 0MB | Util   0% | Total 16280MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Fb8wfbN00Jj",
        "colab_type": "code",
        "outputId": "2cf5322e-0619-4f26-c6ad-5369b0966601",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), input_shape=X.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(64))\n",
        "model.add(Dense(64))\n",
        "\n",
        "model.add(Dense(y.shape[1]))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X, y, batch_size=128, epochs=35, validation_split=0.3)\n",
        "\n",
        "model_path = r'/content/drive/My Drive'\n",
        "model.save(os.path.join(\n",
        "    model_path,\n",
        "    f\"image_classification_model_{datetime.datetime.now().strftime('%Y-%m-%d')}.model\")\n",
        ")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Train on 30799 samples, validate on 13201 samples\n",
            "Epoch 1/35\n",
            "30799/30799 [==============================] - 44s 1ms/sample - loss: 0.1652 - acc: 0.9524 - val_loss: 0.0147 - val_acc: 0.9978\n",
            "Epoch 2/35\n",
            "30799/30799 [==============================] - 38s 1ms/sample - loss: 0.0085 - acc: 0.9980 - val_loss: 0.0182 - val_acc: 0.9961\n",
            "Epoch 3/35\n",
            "30799/30799 [==============================] - 38s 1ms/sample - loss: 0.0074 - acc: 0.9980 - val_loss: 0.0321 - val_acc: 0.9938\n",
            "Epoch 4/35\n",
            "30799/30799 [==============================] - 38s 1ms/sample - loss: 0.0222 - acc: 0.9948 - val_loss: 0.0983 - val_acc: 0.9726\n",
            "Epoch 5/35\n",
            "30799/30799 [==============================] - 38s 1ms/sample - loss: 0.0115 - acc: 0.9971 - val_loss: 0.0111 - val_acc: 0.9984\n",
            "Epoch 6/35\n",
            "30799/30799 [==============================] - 38s 1ms/sample - loss: 0.0017 - acc: 0.9994 - val_loss: 0.0072 - val_acc: 0.9987\n",
            "Epoch 7/35\n",
            "30799/30799 [==============================] - 38s 1ms/sample - loss: 0.0018 - acc: 0.9994 - val_loss: 0.0058 - val_acc: 0.9989\n",
            "Epoch 8/35\n",
            "30799/30799 [==============================] - 36s 1ms/sample - loss: 0.0016 - acc: 0.9995 - val_loss: 0.0067 - val_acc: 0.9989\n",
            "Epoch 9/35\n",
            "30799/30799 [==============================] - 36s 1ms/sample - loss: 8.9289e-04 - acc: 0.9997 - val_loss: 0.0122 - val_acc: 0.9989\n",
            "Epoch 10/35\n",
            "30799/30799 [==============================] - 36s 1ms/sample - loss: 6.1769e-05 - acc: 1.0000 - val_loss: 0.0107 - val_acc: 0.9990\n",
            "Epoch 11/35\n",
            "30799/30799 [==============================] - 36s 1ms/sample - loss: 7.9314e-06 - acc: 1.0000 - val_loss: 0.0105 - val_acc: 0.9991\n",
            "Epoch 12/35\n",
            "30799/30799 [==============================] - 36s 1ms/sample - loss: 4.0617e-06 - acc: 1.0000 - val_loss: 0.0104 - val_acc: 0.9991\n",
            "Epoch 13/35\n",
            "30799/30799 [==============================] - 36s 1ms/sample - loss: 3.2855e-06 - acc: 1.0000 - val_loss: 0.0106 - val_acc: 0.9991\n",
            "Epoch 14/35\n",
            "30799/30799 [==============================] - 36s 1ms/sample - loss: 2.4799e-06 - acc: 1.0000 - val_loss: 0.0107 - val_acc: 0.9991\n",
            "Epoch 15/35\n",
            "30799/30799 [==============================] - 36s 1ms/sample - loss: 2.1958e-06 - acc: 1.0000 - val_loss: 0.0108 - val_acc: 0.9991\n",
            "Epoch 16/35\n",
            "30799/30799 [==============================] - 36s 1ms/sample - loss: 1.7861e-06 - acc: 1.0000 - val_loss: 0.0107 - val_acc: 0.9991\n",
            "Epoch 17/35\n",
            "30799/30799 [==============================] - 36s 1ms/sample - loss: 1.6619e-06 - acc: 1.0000 - val_loss: 0.0110 - val_acc: 0.9991\n",
            "Epoch 18/35\n",
            "30799/30799 [==============================] - 36s 1ms/sample - loss: 1.3560e-06 - acc: 1.0000 - val_loss: 0.0110 - val_acc: 0.9991\n",
            "Epoch 19/35\n",
            "30799/30799 [==============================] - 36s 1ms/sample - loss: 1.1444e-06 - acc: 1.0000 - val_loss: 0.0110 - val_acc: 0.9991\n",
            "Epoch 20/35\n",
            "30799/30799 [==============================] - 36s 1ms/sample - loss: 1.0405e-06 - acc: 1.0000 - val_loss: 0.0111 - val_acc: 0.9991\n",
            "Epoch 21/35\n",
            "30799/30799 [==============================] - 36s 1ms/sample - loss: 8.9306e-07 - acc: 1.0000 - val_loss: 0.0112 - val_acc: 0.9991\n",
            "Epoch 22/35\n",
            "30799/30799 [==============================] - 36s 1ms/sample - loss: 7.8951e-07 - acc: 1.0000 - val_loss: 0.0114 - val_acc: 0.9991\n",
            "Epoch 23/35\n",
            "30799/30799 [==============================] - 36s 1ms/sample - loss: 6.8412e-07 - acc: 1.0000 - val_loss: 0.0114 - val_acc: 0.9991\n",
            "Epoch 24/35\n",
            "30799/30799 [==============================] - 36s 1ms/sample - loss: 6.0780e-07 - acc: 1.0000 - val_loss: 0.0116 - val_acc: 0.9991\n",
            "Epoch 25/35\n",
            "30799/30799 [==============================] - 36s 1ms/sample - loss: 5.0745e-07 - acc: 1.0000 - val_loss: 0.0117 - val_acc: 0.9991\n",
            "Epoch 26/35\n",
            "30799/30799 [==============================] - 36s 1ms/sample - loss: 4.5676e-07 - acc: 1.0000 - val_loss: 0.0118 - val_acc: 0.9991\n",
            "Epoch 27/35\n",
            "30799/30799 [==============================] - 36s 1ms/sample - loss: 3.9816e-07 - acc: 1.0000 - val_loss: 0.0120 - val_acc: 0.9991\n",
            "Epoch 28/35\n",
            "30799/30799 [==============================] - 36s 1ms/sample - loss: 3.5000e-07 - acc: 1.0000 - val_loss: 0.0120 - val_acc: 0.9991\n",
            "Epoch 29/35\n",
            "30799/30799 [==============================] - 36s 1ms/sample - loss: 3.1026e-07 - acc: 1.0000 - val_loss: 0.0122 - val_acc: 0.9991\n",
            "Epoch 30/35\n",
            "30799/30799 [==============================] - 37s 1ms/sample - loss: 2.6931e-07 - acc: 1.0000 - val_loss: 0.0121 - val_acc: 0.9991\n",
            "Epoch 31/35\n",
            "30799/30799 [==============================] - 36s 1ms/sample - loss: 2.3451e-07 - acc: 1.0000 - val_loss: 0.0124 - val_acc: 0.9991\n",
            "Epoch 32/35\n",
            "30799/30799 [==============================] - 36s 1ms/sample - loss: 2.0845e-07 - acc: 1.0000 - val_loss: 0.0125 - val_acc: 0.9991\n",
            "Epoch 33/35\n",
            "30799/30799 [==============================] - 36s 1ms/sample - loss: 1.8080e-07 - acc: 1.0000 - val_loss: 0.0126 - val_acc: 0.9991\n",
            "Epoch 34/35\n",
            "30799/30799 [==============================] - 37s 1ms/sample - loss: 1.5582e-07 - acc: 1.0000 - val_loss: 0.0127 - val_acc: 0.9991\n",
            "Epoch 35/35\n",
            "30799/30799 [==============================] - 37s 1ms/sample - loss: 1.4055e-07 - acc: 1.0000 - val_loss: 0.0127 - val_acc: 0.9991\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMGU5j0OnE3l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_path = r'/content/drive/My Drive/OCR scripts'\n",
        "model.save(os.path.join(\n",
        "    model_path,\n",
        "    f\"image_classification_model_{datetime.datetime.now().strftime('%Y-%m-%d')}.model\")\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUXrjhXX91Q8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\n",
        "    f\"image_classification_model_{datetime.datetime.now().strftime('%Y-%m-%d')}.model\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNGUbvbn34Dv",
        "colab_type": "code",
        "outputId": "ae53c8a2-fe84-4374-b7f4-ca4d93bda05d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import cv2\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "categories = ['BAY', 'BBL', 'GSB', 'KBANK', 'KTB', 'Others', 'SCB', 'TBANK', 'TMB']\n",
        "\n",
        "def prepare(filepath):\n",
        "    IMG_SIZE = 100\n",
        "    img_array = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
        "    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE)) \n",
        "    return new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 1) \n",
        "\n",
        "model = tf.keras.models.load_model(\"/content/Image_Classification.model\")\n",
        "prediction = model.predict([prepare('/content/678941063_14863738349228379046.jpeg')])\n",
        "print(prediction[0])\n",
        "print(categories[np.argmax(prediction[0])])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "KBANK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOUpHJFt4YwW",
        "colab_type": "code",
        "outputId": "36b06b17-6213-4d5c-ac30-d44bdd41982f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "prediction[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 1., 0., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    }
  ]
}